"OGP Interface" Application Project overview

Overview of feature requirements
1. GUI
2. Pandas Python Library
3. Parsing script
4. Graph

Detailed features
1. GUI
    1.1 Allow user to view measurements of current shot in a 2D grid (emulate QC-Calc)
        1.1.1 User can "review" the shot of data before sending it to SFOL
    1.2 Allow user to omit, remove individual measurements from the shot before sending it to SFOL
        1.2.1 Allows for filtering of step edits, random testing of new routines, etc
    1.3 Tkinter [In Process]
        1.3.1 Treeview widget to represent data in a grid [In Process]
        1.3.2 Button widget to "Submit shot", "Delete individual measurement(s)"

2. Pandas
    2.1 Collect individual measurements into a Dataframe
        2.1.1 Each dataframe created per OGP program
        2.1.2 Header information collected per part by the given work order number as user input, product codes need to be marshalled against available product codes in SFOL
    2.2 Ingest measurements from OGP data export xls file, delete tables (? Or delete entire workbook)

3. Parsing script [Complete]
    3.1 Continuous loop to check for QC.STA file in the working directory [Complete]
    3.2 Interpret the plain text in QC.STA (measurement data, header information for the shot) [Complete]
        3.2.1 str.split(sep=None, maxsplit=- 1)
            3.2.1.1 Call this on the text file to delimit text blocks by "END!". This text block is considered one set of measurements on a given part for each dimension
            3.2.1.2 Split the text block by carriage return/newline. Each row is distinct and pipe-delimited "|". A match statement can be used to process each row accordingly
            3.2.1.3 Brief row definitions: "Name" can be used to define individual tables similar to how QC-Calc establishes individual *.qcc files. "Date" and "Time" can be combined to provide a timestamp of the measurement record. "DATA" rows provide either shot identifying information, or measurement results. The second field in "DATA" rows indicate which one it is. "DATA|FACTOR" rows are header rows, while the other "DATA|DimensionName" rows are measurement records.
    3.3 Convert the text to equivalent 2D array "measurement records" similar to QC-Calc [Complete]

4. Graph [In Process] (2.0 feature?)
    4.1 Replicate the graphing display of QC-Calc [In Process]
        4.1.1 Leverage Matplotlib [In Process]
        4.1.2 Allow user to adjust the # of consecutive measurements to render (default = 10, up to 96?)
    4.2 Render measurements as in or out of spec
        4.2.1 Fetch specs from DaedriVictus based on product code
        4.2.2 Refresh the graphs upon ingest of another measurement record 
            4.2.2.1 This should be fairly easily leveraged with matplotlibs built in event handler.


        
Notes:
    -Difficulty parsing QC.STA into Measurement Values table format, then from Measurement Values table format to 2D grid. 
    Consider translating the existing QC.STA file output directly into a 2D grid (QC-Calc's format) [Rejected]
    
    -If measuring consecutive parts and the DATA|FACTOR rows aren't present, use a query to find the most recent set of 
    data factors and use those for each consecutive part measurement [In Process]

    - Tkinter's .mainloop() function is blocking, multi threading is highly discouraged due to the nature of Tkinter's event loop. Developers advise others to explore other options such as:
        - bypassing tkinter's .mainloop() entirely in favor of .update() and update_idletasks() which are manual function calls to push the event loop forward
            - .update() and update_idletasks() might make the GUI appear to be frozen and unresponsive in between these function calls, as GUI events will pile up in the event queue
        - exiting the .mainloop() event loop with .quit() to call other functions, and then calling .mainloop() again to re-enter the event loop
            - same issue here as with .update*() function calls. This might be negligible based on the scope of this project. This may also require extensive testing/error handling to ensure the program always returns to the event loop no matter what.
        - calling tkinter's built-in .after() function, which schedules a function to be called within the event loop, this allows tkinter to handle background tasks within a single threaded application by scheduling a function to be called after a timed delay



A note on workflow for myself
to properly function, first the "sheet one" or main shot must be read into the script to gather the critical info from the last line
In this case, the first call is to grabdata() with the parameters of the sheet in either position 1 or 0, depending on if the OGP export requires sheet one to remain.
From there we can now query both the sql database of part #'s to determine if it is a two-part shot and which type, as well as query powershop using the work order number 
to retrieve header info and ensure that all of the data matches up, then store the necessary info for a filename at the end of the process. 
(NOTE1, this step should also verify that the part # in fact exists as well and should it not, generate a dialogue box to gather the correct part #)
Should there be a two part shot then grabdata() will need to be executed a second time with the sheet positioned after the first shot. After we have both shots attached to variables
as dataframes we will then need to parse both through formatQCtoDF(). Once they are formatted, there will need to be a logic set(if statement or for loop?)
to assign the correct two part function and execute this. 
After this step, in the case of both single and two part shots, we will need to take the previous powershop data, and use it to confirm all entered data is correct and for a filename
Once that is completed the file will need to be moved to the appropriate folder. NOTE2, perhaps we should leverage an event listener at this point, to verify that the file has been placed into the backup folder. 
once we confirm it has been backed up, then we can finish the program by deleting the sheets of the ogptest.xls file.


watchdog library has not been added for handling when the file is confirmed to be added to the correct place and uploaded to SFOL
so we need to do that


validations because fucking validations man
in theory we can just spit the data to the project tool sheet #2
in practice i dont know

QC-Calc doesn't seem to have a global default for # of columns to send over to the export file. There are extra textfactor columns being generated in some of the worksheets. Need to determine if there's a way to set a global template for NumFactor/TextFactor columns for all programs in QC-Calc

Typical workflow
1. main()               Entry point to workflow
2. grabData()           Read measurements of current worksheet #1 into a dataframe
                        Collect (product code, work order) from the last line
3. checkPartno()        Confirm product code exists & determine if 2-part program
                        Compare to product codes in SQL db
                        If doesn't exist, prompt user for a product code
                        If this is 2-part program, call step 2 again to create another dataframe
4. grabfilenameData()   Query SPC DailyTracker with the given workorder collected in step #3 for header information
5. formatQCtoDF()       input dataframe(s) and "processes" the formatting to comply with SFOL
6. namer()              Gives the filename